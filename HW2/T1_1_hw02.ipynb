{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "\n",
    "## Due September 14th before Midnight\n",
    "\n",
    "## Readings: Lecture 03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "Let $u,v\\in\\mathbb{R}^n$ and suppose $\\Vert u\\Vert=1$. \n",
    "\n",
    "### Part A\n",
    "\n",
    "Show that $(u^Tv)u$ is the orthogonal projection of $v$ onto $span(\\{u\\})$.\n",
    "\n",
    "### Part B\n",
    "\n",
    "Show that $\\Vert v - (u^Tv) u\\Vert^2 = \\Vert v\\Vert^2-(u^Tv)^2$.\n",
    "\n",
    "### Part C\n",
    "\n",
    "Use Part B to conclude that $\\vert u^T v\\vert \\leq \\Vert v\\Vert$ for any $u,v\\in\\mathbb{R}^n$ with $u$ a unit vector.\n",
    "\n",
    "### Part D\n",
    "\n",
    "Use Part C to prove the **Cauchy-Schwarz inequality**:\n",
    "\n",
    "$$\n",
    "\\vert x^Ty\\vert\\leq \\Vert x\\Vert\\Vert y\\Vert\n",
    "$$\n",
    "\n",
    "for all $x,y\\in\\mathbb{R}^n$, and equality holds if and only if $x=cy$ or $y=cx$ for some $c\\in\\mathbb{R}^n$.\n",
    "\n",
    "#### Note: \n",
    "\n",
    "This Cauchy-Schwarz inequality suggests that identify the quantity\n",
    "\n",
    "$$\n",
    "-1\\leq \\frac{x^Ty}{\\Vert x\\Vert \\Vert y\\Vert}\\leq 1\n",
    "$$\n",
    "\n",
    "as the **cosine** of the angle between $x\\not=0$ and $y\\not=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution to Problem 1\n",
    "### Part A\n",
    "If we can divide vector $v$ into two parts, and make sure one is in the space of $span(\\{u\\})$, the other is orthogonal to $span(\\{u\\})$, then we can assert that the one in the space of $span(\\{u\\})$ is the projection.\n",
    "So we have:\n",
    "$$v=((u^Tv)u) + (v - (u^Tv)u)$$\n",
    "Since $(u^Tv)$ is a constant, we can easily see that $((u^Tv)u)$ is in the space of $span(\\{u\\})$.\n",
    "And we can prove the remaining part is just orthogonal to $span(\\{u\\})$. Since $span(\\{u\\})=\\alpha\\ u,\\ \\alpha\\in R$. What we should prove is that $(v - (u^Tv)u)$ is orthogonal to $u$. So we have:\n",
    "$$u^T(v-(u^Tv)u)$$\n",
    "$$=u^Tv-(u^Tv)u^Tu$$\n",
    "$$=u^Tv-(u^Tv)$$\n",
    "$$=0$$\n",
    "$$$$\n",
    "That's the only expression we have. If we suppose $v=\\alpha_1u+\\epsilon_1=\\alpha_2u+\\epsilon_2$ and $\\epsilon_1^Tu=\\epsilon_2^Tu=0$ and $(\\alpha_1,\\epsilon_1)\\neq(\\alpha_2,\\epsilon_2)$. Then:\n",
    "$$(v-\\alpha_1u)^Tu=v^Tu-\\alpha_1=v^Tu-\\alpha_2$$\n",
    "$$\\alpha_1=\\alpha_2$$\n",
    "Then:\n",
    "$$\\epsilon_1=v-\\alpha_1u=v-\\alpha_2u=\\epsilon_2$$\n",
    "That leads to a contradiction with $(\\alpha_1,\\epsilon_1)\\neq(\\alpha_2,\\epsilon_2)$.\n",
    "\n",
    "### Part B\n",
    "$$||v-(u^Tv)u||^2$$\n",
    "$$=(v-(u^Tv)u)^T(v-(u^Tv)u)$$\n",
    "$$=v^Tv-((u^Tv)u))^Tv-v^T((u^Tv)u)+(u^Tv)^2u^Tu$$\n",
    "$$=v^Tv-2(u^Tv)(u^Tv)+(u^Tv)^2$$\n",
    "$$=||v||^2-(u^Tv)^2$$\n",
    "\n",
    "### Part C\n",
    "From Part B, we have:\n",
    "$$||v||^2-(u^Tv)^2$$\n",
    "$$=||v-(u^Tv)u||^2\\geq 0$$\n",
    "That leads to:\n",
    "$$|u^Tv|\\leq||v||$$\n",
    "\n",
    "### Part D\n",
    "If $x$ and $y$ are all zero vectors, obviously the equation holds and the equation condition holds.  \n",
    "If one of $x$ and $y$ is not zero vector, we can suppose that is $x$.(If $y$ is the one not being zero vector, just the same situation.)  \n",
    "From Part C, we can let $u=\\frac{x}{||x||}\\ and\\ v=y$, then we have:\n",
    "$$|\\frac{x}{||x||}^Ty|\\leq||y||$$\n",
    "That leads to:\n",
    "$$|x^Ty|\\leq||x||||y||$$  \n",
    "From Part C, we can see when the equation holds, we have:\n",
    "$$||v-(u^Tv)u||^2=0$$\n",
    "$$||y-(\\frac{x^T}{||x||}y)\\frac{x}{||x||}||^2=0$$\n",
    "$$y-\\frac{(x^Ty)}{||x||^2}x=0$$  \n",
    "If we choose $c$ to be $\\frac{(x^Ty)}{||x||^2}$, that is:  \n",
    "$$y=cx$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "Use the Cauchy-Schwarz inequality to prove the **triangle inequality**\n",
    "\n",
    "$$\n",
    "\\Vert x- y\\Vert \\leq \\Vert x\\Vert + \\Vert y\\Vert\n",
    "$$\n",
    "\n",
    "for all $x,y\\in\\mathbb{R}^n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution to Problem 2\n",
    "We have:\n",
    "$$||x-y||^2$$\n",
    "$$=x^Tx-2x^Ty+y^Ty$$\n",
    "$$=||x||^2-2x^Ty+||y||^2$$\n",
    "$$\\leq||x||^2+2||x||||y||+||y||^2\\ Applying\\ the\\ Cauchy\\ Inequality$$\n",
    "$$=(||x||+||y||)^2$$\n",
    "That leads to:\n",
    "$$||x-y||\\leq||x||+||y||$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3:\n",
    "\n",
    "Let $\\mathcal{V}$ be a subspace of $\\mathbb{R}^n$. \n",
    "\n",
    "### Part A\n",
    "\n",
    "Suppose $x\\in\\mathbb{R}^n$ and let $x^\\ast$ be the orthogonal projection of $x$ onto $\\mathcal{V}$. Show that\n",
    "\n",
    "$$\n",
    "\\Vert x-x^\\ast\\Vert^2=\\Vert x\\Vert^2-\\Vert x^\\ast\\Vert^2\n",
    "$$\n",
    "\n",
    "### Part B\n",
    "\n",
    "If $\\{u_i\\}_{i=1}^k$ is an orthonormal basis for $\\mathcal{V}$, $x\\in\\mathbb{R}^n$, and $x^\\ast$ is the projection of $x$ onto $\\mathcal{V}$, show that\n",
    "\n",
    "$$\n",
    "\\Vert x^\\ast\\Vert^2 = \\sum_{i=1}^k \\vert u_i^T x\\vert^2\n",
    "$$\n",
    "\n",
    "\n",
    "### Part C\n",
    "\n",
    "Use Part A to show that\n",
    "\n",
    "$$\n",
    "\\Vert x^\\ast\\Vert \\leq \\Vert x\\Vert.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution to Problem 3\n",
    "### Part A\n",
    "Since $x^*$ is the orthogonal projection of $x$ onto $\\mathcal{V}$, we have: $(x-x^*)^Tx^*=0$, since $x^*$ is in $\\mathcal{V}$.\n",
    "That is $x^Tx^*=x^{*T}x^*$. So we have:\n",
    "$$||x-x^*||^2$$\n",
    "$$=(x-x^*)^T(x-x^*)$$\n",
    "$$=x^Tx-2x^Tx^*+x^{*T}x^*$$\n",
    "$$=x^Tx-x^{*T}x^*\\ By\\ applying\\ the\\ equation\\ above$$\n",
    "$$=||x||^2-||x^*||^2$$\n",
    "\n",
    "### Part B\n",
    "Since $x^*$ is the projection of $x$ onto $\\mathcal{V}$, $x^*$ is on the space of $span(\\{u_i\\}_{i=1}^k)$. Suppose that:\n",
    "$$x^*=\\sum_{i=1}^k\\alpha_i u_i,\\ \\alpha_i\\in R\\ for\\ i=1,2,...,k$$\n",
    "That is:\n",
    "$$x=x-x^*+\\sum_{i=1}^k\\alpha_i u_i$$\n",
    "We mutiply it by $u_j^T$ on the left side, then we have:\n",
    "$$u_j^Tx=u_j^T(x-x^*)+\\sum_{i=1}^k\\alpha_i u_j^T u_i$$\n",
    "Since $x-x^*$ is orthogonal to $u_j$ and $u_j^Tu_i=1\\ when\\ j=i\\ and\\ u_j^Tu_i=0\\ when\\ j\\neq i$, we have:\n",
    "$$u_j^Tx=\\alpha_j$$\n",
    "We can spread $||x^*||^2$:\n",
    "$$||x^*||^2=(\\sum_{i=1}^k \\alpha_iu_i^T)(\\sum_{j=1}^k \\alpha_ju_j)$$\n",
    "$$=\\sum_{1\\leq i,j\\leq k}\\alpha_i \\alpha_ju_i^Tu_j$$\n",
    "$$=\\sum_{i=1}^k\\alpha_i^2||u_i||^2\\ since\\ u_i^Tu_j=0\\ when\\ i\\neq j$$\n",
    "$$=\\sum_{i=1}^k\\alpha_i^2$$\n",
    "$$=\\sum_{i=1}^k|u_i^Tx|^2$$\n",
    "\n",
    "### Part C\n",
    "From Part A, we have:\n",
    "$$\\Vert x\\Vert^2-\\Vert x^\\ast\\Vert^2$$\n",
    "$$=\\Vert x-x^\\ast\\Vert^2\\geq 0$$\n",
    "That leads to:\n",
    "$$\\Vert x^*\\Vert \\leq \\Vert x \\Vert$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "\n",
    "The $n$ by $n$ **identity matrix** is the matrix $I\\in\\mathbb{R}^{n\\times n}$ with entries\n",
    "$$\n",
    "I_{i,\\: j} = \\left\\{\\begin{array}{cl}1&\\text{if }i=j\\\\0&\\text{ if }i\\not=j\\end{array}\\right.\n",
    "$$\n",
    "That is, each **diagonal entry** satisfies $I_{i,\\:i}=1$ and each **off-diagonal entry** satisfies $I_{i,\\:j}=0$.\n",
    "\n",
    "We say that an $n$ by $n$ matrix is **orthogonal** if its columns form an orthonormal collection.\n",
    "\n",
    "For the next parts, let $U\\in\\mathbb{R}^{n\\times n}$\n",
    "\n",
    "### Part A\n",
    "\n",
    "Show that $U$ is orthogonal if and only if $U^TU=I$.\n",
    "\n",
    "### Part B\n",
    "\n",
    "Show that if $U^TU=I$ if and only if $(Ux)^T(Uy)=x^Ty$ for all $x,y\\in\\mathbb{R}^n$\n",
    "\n",
    "### Part C\n",
    "\n",
    "Show that $(Ux)^T(Uy)=x^Ty$ for all $x,y\\in\\mathbb{R}^n$ if and only if $\\Vert Ux\\Vert=\\Vert x\\Vert$ for all $x\\in\\mathbb{R}^n$.\n",
    "\n",
    "#### Hint: \n",
    "\n",
    "The matrix\n",
    "\n",
    "$$\n",
    "A=\\begin{pmatrix}\n",
    "0 & -1\\\\\n",
    "1 & 0\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "is an example of a matrix such that $x^TAx=0$ for all $x\\in\\mathbb{R}^2$, but $A\\not=0$.\n",
    "\n",
    "To get the result, show that $x^TAy = \\frac{1}{2}\\left[(x+y)^TA(x+y)-x^TAx-y^TAy\\right]$ for any $x,y\\in\\mathbb{R}^n$ when $A$ is a symmetric $n$ by $n$ matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution to Problem 4\n",
    "\n",
    "### Part A\n",
    "$$$$\n",
    "Sufficient Condition:\n",
    "\n",
    "\n",
    "We suppose $U=(u_1,u_2,...,u_n)$ and the vectors $\\{u_i\\}_{i=1}^n$ are column vectors in the space of $R^{n\\times 1}$.\n",
    "\n",
    "We have:\n",
    "$$(u_1,u_2,...,u_n)^T(u_1,u_2,...,u_n)=I$$\n",
    "$$\\begin{pmatrix}\n",
    "{u_1^T}\\\\\n",
    "{u_2^T}\\\\\n",
    "{\\vdots}\\\\\n",
    "{u_n^T}\\\\\n",
    "\\end{pmatrix}(u_1,u_2,...,u_n)=I$$\n",
    "$$\\begin{pmatrix}\n",
    "{u_1^Tu_1}&{u_1^Tu_2}&{\\cdots}&{u_1^Tu_n}\\\\\n",
    "{u_2^Tu_1}&{u_2^Tu_2}&{\\cdots}&{u_1^Tu_n}\\\\\n",
    "{\\vdots}&{\\vdots}&{\\ddots}&{\\vdots}\\\\\n",
    "{u_n^Tu_1}&{u_n^Tu_2}&{\\cdots}&{u_n^Tu_n}\\\\\n",
    "\\end{pmatrix}=I$$\n",
    "That is:\n",
    "$$\\begin{equation}\n",
    "u_i^Tu_j=\n",
    "\\end{equation} \n",
    "\\begin{cases}\n",
    "1,\\ when\\ i=j\\\\\n",
    "0,\\ when\\ i\\neq j\\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "which indicates that $\\{u_i\\}_{i=1}^n$ are orthogonal vectors.  \n",
    "\n",
    "\n",
    "Necessary Condition:\n",
    "\n",
    "\n",
    "We suppose $U=(u_1,u_2,...,u_n)$ and the vectors $\\{u_i\\}_{i=1}^n$ are the orthogonal column vectors in the space of $R^{n\\times 1}$. If $U$ consists of orthogonal line vectors, we can find it equivalent to having the assumption of orthogonal column vectors using sufficiency and necessity after proving them.  \n",
    "\n",
    "\n",
    "Since $\\{u_i\\}_{i=1}^n$ are orthogonal vectors, we have:\n",
    "$$\\begin{equation}\n",
    "u_i^Tu_j=\n",
    "\\end{equation} \n",
    "\\begin{cases}\n",
    "1,\\ when\\ i=j\\\\\n",
    "0,\\ when\\ i\\neq j\\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "We can calculate directly:\n",
    "$$U^TU$$\n",
    "$$=\\begin{pmatrix}\n",
    "{u_1^T}\\\\\n",
    "{u_2^T}\\\\\n",
    "{\\vdots}\\\\\n",
    "{u_n^T}\\\\\n",
    "\\end{pmatrix}(u_1,u_2,...,u_n)$$\n",
    "$$=\\begin{pmatrix}\n",
    "{u_1^Tu_1}&{u_1^Tu_2}&{\\cdots}&{u_1^Tu_n}\\\\\n",
    "{u_2^Tu_1}&{u_2^Tu_2}&{\\cdots}&{u_1^Tu_n}\\\\\n",
    "{\\vdots}&{\\vdots}&{\\ddots}&{\\vdots}\\\\\n",
    "{u_n^Tu_1}&{u_n^Tu_2}&{\\cdots}&{u_n^Tu_n}\\\\\n",
    "\\end{pmatrix}$$\n",
    "$$=I$$\n",
    "\n",
    "Finally if $U$ consists of orthogonal line vectors, $U^T$ consists of orthogonal column vectors. And that leads to $(U^T)^T(U^T)=I$.\n",
    "We have:\n",
    "$$UU^T=I$$\n",
    "$$U^T=U^{-1},\\ mutiply\\ U^{-1}\\ on\\ the\\ left$$\n",
    "$$U^TU=I,\\ mutiply\\ U\\ on\\ the\\ right$$\n",
    "\n",
    "\n",
    "### Part B\n",
    "\n",
    "Necessity:\n",
    "\n",
    "$$(Ux)^T(Uy)=x^T(U^TU)y$$\n",
    "$$=x^Ty$$\n",
    "\n",
    "Sufficiency:\n",
    "\n",
    "\n",
    "We suppose $\\{e_i\\}_{i=1}^n$ to be the element vectors, which means $e_i$ only has value of 1 on the ith entry with values of zero on all the other entries.\n",
    "\n",
    "We write $U$ as $(u_1,u_2,...,u_n)$\n",
    "\n",
    "We choose $x$ to be $\\{e_i\\}_{i=1}^n$ and $y$ to be $\\{e_j\\}_{j=1}^n$, then we have:\n",
    "$$((u_1,...,u_n)e_i)^T((u_1,...,u_n)e_j)$$\n",
    "$$=u_i^Tu_j$$\n",
    "\n",
    "The result matrix has the only element on the ith line the jth and column.\n",
    "And we have:\n",
    "$$\\begin{equation}\n",
    "e_i^Te_j=\n",
    "\\end{equation} \n",
    "\\begin{cases}\n",
    "1,\\ when\\ i=j\\\\\n",
    "0,\\ when\\ i\\neq j\\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "That leads to:\n",
    "$$\\begin{equation}\n",
    "u_i^Tu_j=\n",
    "\\end{equation} \n",
    "\\begin{cases}\n",
    "1,\\ when\\ i=j\\\\\n",
    "0,\\ when\\ i\\neq j\\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "So $\\{u_i\\}_{i=1}^n$ are orthogonal vectors, which means $U$ is an orthogonal matrix.\n",
    "\n",
    "### Part C\n",
    "\n",
    "Necessity:\n",
    "\n",
    "\n",
    "If we choose $y=x$, the proof is obvious.\n",
    "\n",
    "\n",
    "Sufficiency:\n",
    "\n",
    "We have:\n",
    "$$\\Vert Ux\\Vert^2=\\Vert x\\Vert^2$$\n",
    "$$(Ux)^TUx=x^Tx$$\n",
    "$$x^TU^TUx=x^Tx$$\n",
    "We choose $x$ to be $x$ and $y$, then we have:\n",
    "$$x^TU^TUx=x^Tx$$\n",
    "$$y^TU^TUy=y^Ty$$\n",
    "Then we choose $x$ to be $x+y$\n",
    "$$(x+y)^TU^TU(x+y)=(x+y)^T(x+y)$$\n",
    "$$x^TU^TUx+y^TU^TUy+2x^TU^TUy=x^Tx+y^Ty+2x^Ty$$\n",
    "$$x^TU^TUy=x^Ty$$\n",
    "$$(Ux)^T(Uy)=x^Ty$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5\n",
    "\n",
    "Use the Gramm-Schmidt process to get an orthonormal basis for the column space of the design matrix\n",
    "\n",
    "$$\n",
    "X = \\begin{pmatrix}\n",
    "1 & 0 & -1 & 1\\\\\n",
    "1 & 1 & 0 & 1\\\\\n",
    "1 & 2 & 1 & 0\\\\\n",
    "1 & -1 & -2 & 1\\\\\n",
    "1 & 0 & -1 & 0\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "Use this orthonormal basis to compute a least squares solution $\\beta^\\ast\\in\\mathbb{R}^n$ given this design matrix and the reponse vector\n",
    "\n",
    "$$\n",
    "y=\\begin{pmatrix}\n",
    "1\\\\\n",
    "0\\\\\n",
    "2\\\\\n",
    "3\\\\\n",
    "1\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution to Problem 5\n",
    "\n",
    "We write $X$ as $(x_1,x_2,x_3,x_4)$, which means:\n",
    "$$x_1=\\begin{pmatrix}1\\\\1\\\\1\\\\1\\\\1\\\\\\end{pmatrix}x_2=\\begin{pmatrix}0\\\\1\\\\2\\\\-1\\\\0\\\\\\end{pmatrix}x_3=\\begin{pmatrix}-1\\\\0\\\\1\\\\-2\\\\-1\\\\\\end{pmatrix}x_4=\\begin{pmatrix}1\\\\1\\\\0\\\\1\\\\0\\\\\\end{pmatrix}$$\n",
    "We have:\n",
    "$$\\beta_1=x_1=\\begin{pmatrix}1\\\\1\\\\1\\\\1\\\\1\\\\\\end{pmatrix}$$\n",
    "$$\\beta_2=x_2-\\frac{x_2^T\\beta_1}{\\beta_1^T\\beta_1}\\beta_1=\\begin{pmatrix}-\\frac{2}{5}\\\\\\frac{3}{5}\\\\\\frac{8}{5}\\\\-\\frac{7}{5}\\\\-\\frac{2}{5}\\\\\\end{pmatrix}=x_2-\\frac{2}{5}x_1$$\n",
    "$$\\beta_3=x_3-\\frac{x_3^T\\beta_1}{\\beta_1^T\\beta_1}\\beta_1-\\frac{x_3^T\\beta_2}{\\beta_2^T\\beta_2}\\beta_2=\\begin{pmatrix}0\\\\0\\\\0\\\\0\\\\0\\\\\\end{pmatrix}$$\n",
    "$$\\beta_4=x_4-\\frac{x_4^T\\beta_1}{\\beta_1^T\\beta_1}\\beta_1-\\frac{x_4^T\\beta_2}{\\beta_2^T\\beta_2}\\beta_2=\\begin{pmatrix}\\frac{4}{13}\\\\\\frac{7}{13}\\\\-\\frac{3}{13}\\\\\\frac{1}{13}\\\\-\\frac{9}{13}\\\\\\end{pmatrix}=x_4-\\frac{9}{13}x_1+\\frac{3}{13}x_2$$\n",
    "Then we have:\n",
    "$$e_1=\\frac{\\beta_1}{\\Vert\\beta_1\\Vert}=\\begin{pmatrix}\\frac{1}{\\sqrt{5}}\\\\\\frac{1}{\\sqrt{5}}\\\\\\frac{1}{\\sqrt{5}}\\\\\\frac{1}{\\sqrt{5}}\\\\\\frac{1}{\\sqrt{5}}\\\\\\end{pmatrix}$$\n",
    "$$e_2=\\frac{\\beta_2}{\\Vert\\beta_2\\Vert}=\\begin{pmatrix}-\\frac{2}{\\sqrt{130}}\\\\\\frac{3}{\\sqrt{130}}\\\\\\frac{8}{\\sqrt{130}}\\\\-\\frac{7}{\\sqrt{130}}\\\\-\\frac{2}{\\sqrt{130}}\\\\\\end{pmatrix}$$\n",
    "$$e_3=\\frac{\\beta_4}{\\Vert\\beta_4\\Vert}=\\begin{pmatrix}\\frac{4}{\\sqrt{156}}\\\\\\frac{7}{\\sqrt{156}}\\\\-\\frac{3}{\\sqrt{156}}\\\\\\frac{1}{\\sqrt{156}}\\\\-\\frac{9}{\\sqrt{156}}\\\\\\end{pmatrix}$$\n",
    "\n",
    "\n",
    "So what we have for the response vector is:\n",
    "$$v^*=(y^Te_1)e_1+(y^Te_2)e_2+(y^Te_3)e_3$$\n",
    "$$=\\begin{pmatrix}\\frac{7}{5}\\\\\\frac{7}{5}\\\\\\frac{7}{5}\\\\\\frac{7}{5}\\\\\\frac{7}{5}\\\\\\end{pmatrix}+\\begin{pmatrix}\\frac{18}{130}\\\\-\\frac{27}{130}\\\\-\\frac{72}{130}\\\\\\frac{63}{130}\\\\\\frac{18}{130}\\\\\\end{pmatrix}+\\begin{pmatrix}-\\frac{32}{156}\\\\-\\frac{56}{156}\\\\\\frac{24}{156}\\\\-\\frac{8}{156}\\\\\\frac{72}{156}\\\\\\end{pmatrix}$$\n",
    "$$=\\begin{pmatrix}\\frac{4}{3}\\\\\\frac{5}{6}\\\\1\\\\\\frac{11}{6}\\\\2\\\\\\end{pmatrix}$$\n",
    "$$=\\frac{y^T\\beta_1}{||\\beta_1||^2}\\beta_1+\\frac{y^T\\beta_2}{||\\beta_2||^2}\\beta_2+\\frac{y^T\\beta_4}{||\\beta_4||^2}\\beta_4$$\n",
    "$$=\\frac{7}{5}x_1-\\frac{9}{130}(5x_2-2x_1)-\\frac{8}{156}(13x_4-9x_1+3x_2)$$\n",
    "$$=2x_1-\\frac{1}{2}x_2-\\frac{2}{3}x_4$$\n",
    "That leads to:\n",
    "$$\\beta^*=\\begin{pmatrix}\n",
    "2\\\\\n",
    "-\\frac{1}{2}\\\\\n",
    "0\\\\\n",
    "-\\frac{2}{3}\n",
    "\\end{pmatrix}$$"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
